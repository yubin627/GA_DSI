{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use function *multi_merge(train,test,list_of_lag_days,list_of_feature_lists)* to create variations of our datasets.\n",
    "\n",
    "---\n",
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import haversine as hv\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set station coordinates\n",
    "STATIONS = {\n",
    "    1 : (41.995,-87.933),\n",
    "    2 : (41.786,-87.752)\n",
    "}\n",
    "\n",
    "def nearest_station(in_coords):\n",
    "    \n",
    "    dist = {k:hv.haversine(in_coords,v) for k,v in STATIONS.items()}\n",
    "    \n",
    "    return min(dist, key=dist.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train,test data and map nearest weather station\n",
    "train = pd.read_csv(r'.\\data\\train.csv')\n",
    "test = pd.read_csv(r'.\\data\\test.csv')\n",
    "train['nearest_station'] = train.apply(lambda x: nearest_station([x.Latitude, x.Longitude]), axis=1)\n",
    "test['nearest_station'] = test.apply(lambda x: nearest_station([x.Latitude, x.Longitude]), axis=1)\n",
    "train.Date = train.Date.astype('datetime64[ns]')\n",
    "test.Date = test.Date.astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import weather data and convert date type\n",
    "weather = pd.read_csv(r'.\\data\\weather_cleaned_stack_back.csv')\n",
    "weather.drop(columns='Unnamed: 0',inplace=True)\n",
    "weather.Date = weather.Date.astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Address', 'Species', 'Block', 'Street', 'Trap',\n",
       "       'AddressNumberAndStreet', 'Latitude', 'Longitude', 'AddressAccuracy',\n",
       "       'NumMosquitos', 'WnvPresent', 'nearest_station'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Munging weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list=['Tmax','Tmin','Tavg','Depart','DewPoint','WetBulb','Cool']\n",
    "rain_list=['PrecipTotal']\n",
    "day_list=['Sunset','DaylightHrs','StnPressure','SeaLevel','ResultSpeed',\n",
    "          'ResultDir','AvgSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to merge weather features based on date lag\n",
    "def to_merge(train,test,lag,feature_list):\n",
    "    train['date_lag'] = train.Date.map(lambda x : x - timedelta(days=lag))\n",
    "    test['date_lag'] = test.Date.map(lambda x : x - timedelta(days=lag))\n",
    "    feature_list=feature_list+['Date','Station']\n",
    "    train_weather = train.merge(weather[feature_list],left_on=['date_lag','nearest_station'],right_on=['Date','Station'])\n",
    "    test_weather = test.merge(weather[feature_list],left_on=['date_lag','nearest_station'],right_on=['Date','Station'])\n",
    "    train_weather.drop(['Date_y','Station'],axis=1,inplace=True)\n",
    "    train_weather.rename({'Date_x':'Date'},axis=1,inplace=True)\n",
    "    test_weather.drop(['Date_y','Station'],axis=1,inplace=True)\n",
    "    test_weather.rename({'Date_x':'Date'},axis=1,inplace=True)\n",
    "    return(train_weather,test_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to merge multiple weather features with different date lags\n",
    "def multi_merge(train,test,lag_list,list_of_lists):\n",
    "    if len(lag_list)!=len(list_of_lists):\n",
    "        print('Mismatch in list lengths')\n",
    "        return None\n",
    "    else:\n",
    "        for i in range(len(lag_list)):\n",
    "            train,test=to_merge(train,test,lag_list[i],list_of_lists[i])\n",
    "        train['month'] = train.Date.map(lambda x : x.month)\n",
    "        test['month'] = test.Date.map(lambda x : x.month)\n",
    "        return(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_list=[0,3,11]\n",
    "feat_list=[day_list,temp_list,rain_list]\n",
    "train_1,test_1=multi_merge(train,test,lag_list,feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['month','Species','Sunset', 'Street',\n",
    "       'DaylightHrs', 'Tmax', 'Tmin', 'Tavg', 'Depart', 'DewPoint', 'WetBulb',\n",
    "       'Cool', 'PrecipTotal', 'StnPressure', 'SeaLevel', 'ResultSpeed',\n",
    "       'ResultDir', 'AvgSpeed','WnvPresent']\n",
    "# NumMosquitos removed as this feature is not present in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = train_1[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Preparation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chang\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\chang\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\chang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "sm = SMOTE(sampling_strategy=1,random_state=666)\n",
    "\n",
    "train_dummies = pd.get_dummies(train_1,drop_first=True,columns=['Species','Street'])\n",
    "y = train_dummies['WnvPresent']\n",
    "X = train_dummies[[col for col in train_dummies.columns if col != 'WnvPresent']]\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X,y,test_size = 0.3, random_state = 666,stratify=y)\n",
    "train_x=scaler.fit_transform(train_x)\n",
    "test_x=scaler.transform(test_x)\n",
    "sampledX,sampledy = sm.fit_sample(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6484848484848484"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test fit and predict, benchmark\n",
    "lr=LogisticRegression(solver='liblinear')\n",
    "lr.fit(sampledX,sampledy)\n",
    "pred=lr.predict(test_x)\n",
    "recall_score(test_y,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Testing different ranges\n",
    "\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;With recall scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recscore_iter(train,test,lag_list,feature_list):\n",
    "    train_1,test_1=multi_merge(train,test,lag_list,feat_list)\n",
    "    train_1 = train_1[cols]\n",
    "    scaler = StandardScaler()\n",
    "    sm = SMOTE(sampling_strategy=1,random_state=666)\n",
    "\n",
    "    train_dummies = pd.get_dummies(train_1,drop_first=True,columns=['Species','Street'])\n",
    "    train_dummies=train_dummies.astype('float64')\n",
    "    y = train_dummies['WnvPresent']\n",
    "    X = train_dummies[[col for col in train_dummies.columns if col != 'WnvPresent']]\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(X,y,test_size = 0.3, random_state = 666,stratify=y)\n",
    "    train_x=scaler.fit_transform(train_x)\n",
    "    test_x=scaler.transform(test_x)\n",
    "    sampledX,sampledy = sm.fit_sample(train_x,train_y)\n",
    "    \n",
    "    lr=LogisticRegression(solver='liblinear')\n",
    "    lr.fit(sampledX,sampledy)\n",
    "    pred=lr.predict(test_x)\n",
    "    return (recall_score(test_y,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp days recall 1: 0.6787878787878788\n",
      "temp days recall 2: 0.696969696969697\n",
      "temp days recall 3: 0.6727272727272727\n",
      "temp days recall 4: 0.6787878787878788\n",
      "temp days recall 5: 0.6787878787878788\n",
      "temp days recall 6: 0.6666666666666666\n",
      "temp days recall 7: 0.6727272727272727\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,8):\n",
    "    lag_list=[0,i,11]\n",
    "    print('temp days recall ' + str(i) + ': ' + str(recscore_iter(train,test,lag_list,feat_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rain day recall 1: 0.6848484848484848\n",
      "rain day recall 2: 0.6787878787878788\n",
      "rain day recall 3: 0.6909090909090909\n",
      "rain day recall 4: 0.6727272727272727\n",
      "rain day recall 5: 0.703030303030303\n",
      "rain day recall 6: 0.6848484848484848\n",
      "rain day recall 7: 0.696969696969697\n",
      "rain day recall 8: 0.6787878787878788\n",
      "rain day recall 9: 0.6848484848484848\n",
      "rain day recall 10: 0.6787878787878788\n",
      "rain day recall 11: 0.6787878787878788\n",
      "rain day recall 12: 0.6848484848484848\n",
      "rain day recall 13: 0.6787878787878788\n",
      "rain day recall 14: 0.6848484848484848\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,15):\n",
    "    lag_list=[0,4,i]\n",
    "    print('rain day recall '+str(i) + ': ' + str(recscore_iter(train,test,lag_list,feat_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## &nbsp;&nbsp;&nbsp;&nbsp;With ROC_AUC scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocscore_iter(train,test,lag_list,feature_list):\n",
    "    train_1,test_1=multi_merge(train,test,lag_list,feat_list)\n",
    "    train_1 = train_1[cols]\n",
    "    scaler = StandardScaler()\n",
    "    sm = SMOTE(sampling_strategy=1,random_state=666)\n",
    "\n",
    "    train_dummies = pd.get_dummies(train_1,drop_first=True,columns=['Species','Street'])\n",
    "    train_dummies=train_dummies.astype('float64')\n",
    "    y = train_dummies['WnvPresent']\n",
    "    X = train_dummies[[col for col in train_dummies.columns if col != 'WnvPresent']]\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(X,y,test_size = 0.3, random_state = 666,stratify=y)\n",
    "    train_x=scaler.fit_transform(train_x)\n",
    "    test_x=scaler.transform(test_x)\n",
    "    sampledX,sampledy = sm.fit_sample(train_x,train_y)\n",
    "    \n",
    "    lr=LogisticRegression(solver='liblinear')\n",
    "    lr.fit(sampledX,sampledy)\n",
    "    pred=lr.predict_proba(test_x)\n",
    "    return (roc_auc_score(test_y,pd.DataFrame(pred)[1].array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp days roc_auc 1: 0.7750636596970711\n",
      "temp days roc_auc 2: 0.7818405007558004\n",
      "temp days roc_auc 3: 0.775329457954165\n",
      "temp days roc_auc 4: 0.7755790242566272\n",
      "temp days roc_auc 5: 0.7739172779012082\n",
      "temp days roc_auc 6: 0.7743271347556584\n",
      "temp days roc_auc 7: 0.7636140446987452\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,8):\n",
    "    lag_list=[0,i,11]\n",
    "    print('temp days roc_auc ' + str(i) + ': ' + str(rocscore_iter(train,test,lag_list,feat_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rain day roc_auc 1: 0.7762262734475657\n",
      "rain day roc_auc 2: 0.7753923567783627\n",
      "rain day roc_auc 3: 0.7760456929522881\n",
      "rain day roc_auc 4: 0.7767071451035293\n",
      "rain day roc_auc 5: 0.7749074271337412\n",
      "rain day roc_auc 6: 0.7762404764078684\n",
      "rain day roc_auc 7: 0.7793651276744681\n",
      "rain day roc_auc 8: 0.775434965659271\n",
      "rain day roc_auc 9: 0.7771129439693216\n",
      "rain day roc_auc 10: 0.7758610544683529\n",
      "rain day roc_auc 11: 0.7755790242566272\n",
      "rain day roc_auc 12: 0.776210041492934\n",
      "rain day roc_auc 13: 0.7751062685779793\n",
      "rain day roc_auc 14: 0.7769526534173337\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,15):\n",
    "    lag_list=[0,4,i]\n",
    "    print('rain day roc_auc '+str(i) + ': ' + str(rocscore_iter(train,test,lag_list,feat_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "For Kaggle purposes, we should optimise roc_auc score and we use a temp lag of 2 days and a rain lag of 7 days.<br/>\n",
    "For modelling purposes in the business case, we should optimise recall score and we use a temp lag of 2 days and a rain lag of 5 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcols=cols.copy()\n",
    "testcols.remove('WnvPresent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We export our datasets for Kaggle modelling\n",
    "lag_list=[0,2,7]\n",
    "feat_list=[day_list,temp_list,rain_list]\n",
    "train_1,test_1=multi_merge(train,test,lag_list,feat_list)\n",
    "\n",
    "train_1 = train_1[cols]\n",
    "test_1 = test_1[testcols]\n",
    "\n",
    "train_1.to_csv(r'.\\data\\train_lag_Kaggle.csv')\n",
    "test_1.to_csv(r'.\\data\\test_lag_Kaggle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We export our datasets for business modelling\n",
    "lag_list=[0,2,5]\n",
    "feat_list=[day_list,temp_list,rain_list]\n",
    "train_1,test_1=multi_merge(train,test,lag_list,feat_list)\n",
    "\n",
    "train_1 = train_1[cols]\n",
    "test_1 = test_1[testcols]\n",
    "\n",
    "train_1.to_csv(r'.\\data\\train_lag_biz.csv')\n",
    "test_1.to_csv(r'.\\data\\test_lag_biz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
