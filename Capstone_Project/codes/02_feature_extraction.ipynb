{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from config import *\n",
    "from utils import *\n",
    "from data import Fashion_attr_prediction\n",
    "from net import f_model, c_model, p_model\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, deep_module, color_module, pooling_module):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.deep_module = deep_module\n",
    "        self.color_module = color_module\n",
    "        self.pooling_module = pooling_module\n",
    "        self.deep_module.eval()\n",
    "        self.color_module.eval()\n",
    "        self.pooling_module.eval()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # for name, module in list(self.deep_module._modules.items())[:-1]:\n",
    "        #     if name == 'fc':\n",
    "        #         x = x.view(x.size(0), -1)\n",
    "        #     x = module(x)\n",
    "        cls, feat, conv_out = self.deep_module(x)\n",
    "        color = self.color_module(x).cpu().data.numpy()  # N * C * 7 * 7\n",
    "        weight = self.pooling_module(conv_out).cpu().data.numpy()  # N * 1 * 7 * 7\n",
    "        result = []\n",
    "        for i in range(cls.size(0)):\n",
    "            weight_n = weight[i].reshape(-1)\n",
    "            idx = np.argpartition(weight_n, -COLOR_TOP_N)[-COLOR_TOP_N:][::-1]\n",
    "            color_n = color[i].reshape(color.shape[1], -1)\n",
    "            color_selected = color_n[:, idx].reshape(-1)\n",
    "            result.append(color_selected)\n",
    "        return feat.cpu().data.numpy(), result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.torch/models/resnet50-19c8e357.pth\n",
      "102502400it [00:02, 41395473.50it/s]\n"
     ]
    }
   ],
   "source": [
    "main_model = f_model(model_path=DUMPED_MODEL).cuda()\n",
    "color_model = c_model().cuda()\n",
    "pooling_model = p_model().cuda()\n",
    "extractor = FeatureExtractor(main_model, color_model, pooling_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract deep features and color features from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_dataset(loader, deep_feats, color_feats, labels):\n",
    "    for batch_idx, (data, data_path) in enumerate(loader):\n",
    "        data = Variable(data).cuda()\n",
    "        deep_feat, color_feat = extractor(data)\n",
    "        for i in range(len(data_path)):\n",
    "            path = data_path[i]\n",
    "            feature_n = deep_feat[i].squeeze()\n",
    "            color_feature_n = color_feat[i]\n",
    "\n",
    "            deep_feats.append(feature_n)\n",
    "            color_feats.append(color_feature_n)\n",
    "            labels.append(path)\n",
    "\n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print(\"{} / {}\".format(batch_idx * EXTRACT_BATCH_SIZE, len(loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump(pca=False):\n",
    "    all_loader = torch.utils.data.DataLoader(\n",
    "        Fashion_attr_prediction(type=\"all\", transform=data_transform_test),\n",
    "        batch_size=EXTRACT_BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=True\n",
    "    )\n",
    "    deep_feats = []\n",
    "    color_feats = []\n",
    "    labels = []\n",
    "    dump_dataset(all_loader, deep_feats, color_feats, labels)\n",
    "\n",
    "    feat_all = 'output/all_feat_pca.npy'\n",
    "    color_feat_all = 'output/all_color_feat.npy'\n",
    "    feat_list = 'output/all_feat.list'\n",
    "\n",
    "    if pca==True:\n",
    "        # Reduce dimensionality on deep features\n",
    "        scaler = MinMaxScaler(feature_range=[-1, 1])\n",
    "        deep_feats_rescaled = scaler.fit_transform(deep_feats)\n",
    "        pca = PCA(n_components=30)\n",
    "        deep_feats_reduced = pca.fit_transform(deep_feats_rescaled)\n",
    "\n",
    "        with open(feat_list, \"w\") as fw:\n",
    "            fw.write(\"\\n\".join(labels))\n",
    "        np.save(feat_all, np.vstack(deep_feats_reduced))\n",
    "        np.save(color_feat_all, np.vstack(color_feats))\n",
    "        print(\"Dumped to all_feat_pca.npy, all_color_feat.npy and all_feat.list.\")\n",
    "\n",
    "    else:\n",
    "        with open(feat_list, \"w\") as fw:\n",
    "            fw.write(\"\\n\".join(labels))\n",
    "        np.save(feat_all, np.vstack(deep_feats))\n",
    "        np.save(color_feat_all, np.vstack(color_feats))\n",
    "        print(\"Dumped to all_feat.npy, all_color_feat.npy and all_feat.list.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1. (Most efficient) PCA + Naive Query (in the 03_retrieval notebook)\n",
    "#### Call the function (with PCA = True) to save features with dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 139709\n",
      "12800 / 139709\n",
      "25600 / 139709\n",
      "38400 / 139709\n",
      "51200 / 139709\n",
      "64000 / 139709\n",
      "76800 / 139709\n",
      "89600 / 139709\n",
      "102400 / 139709\n",
      "115200 / 139709\n",
      "128000 / 139709\n",
      "Dumped to all_feat_pca.npy, all_color_feat.npy and all_feat.list.\n"
     ]
    }
   ],
   "source": [
    "dump(pca=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2. (Less efficient) Full Features + KMeans Query\n",
    "#### Call the function (with PCA = False) to save full features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 139709\n",
      "12800 / 139709\n",
      "25600 / 139709\n",
      "38400 / 139709\n",
      "51200 / 139709\n",
      "64000 / 139709\n",
      "76800 / 139709\n",
      "89600 / 139709\n",
      "102400 / 139709\n",
      "115200 / 139709\n",
      "128000 / 139709\n",
      "Dumped to all_feat.npy, all_color_feat.npy and all_feat.list.\n"
     ]
    }
   ],
   "source": [
    "dump(pca=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer_with_task(\"Loading feature database\")\n",
    "def load_feat_db():\n",
    "\n",
    "    feat_all = os.path.join(FEATURES_DIR, 'all_feat.npy') \n",
    "    feat_list = os.path.join(FEATURES_DIR, 'all_feat.list')\n",
    "    color_feat = os.path.join(FEATURES_DIR, 'all_color_feat.npy')\n",
    "    \n",
    "    if not os.path.isfile(feat_list) or not os.path.isfile(feat_all) or not os.path.isfile(color_feat):\n",
    "        print(\"No feature db file! Please run feature_extraction notebook first.\")\n",
    "        return\n",
    "    deep_feats = np.load(feat_all)\n",
    "    color_feats = np.load(color_feat)\n",
    "    with open(feat_list) as f:\n",
    "        labels = list(map(lambda x: x.strip(), f.readlines()))\n",
    "    return deep_feats, color_feats, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the KMeans classifier and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading feature database...\n",
      "Loading feature database Done. Time: 2.346 sec\n"
     ]
    }
   ],
   "source": [
    "feats, color_feats,labels = load_feat_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output/kmeans.m']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KMeans(n_clusters=N_CLUSTERS, random_state=0, n_jobs=-1).fit(feats)\n",
    "model_path = os.path.join(OUTPUT_DIR, r'kmeans.m')\n",
    "joblib.dump(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
